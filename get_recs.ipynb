{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and merging csv files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# read in all dfs\n",
    "df = pd.read_csv('perfume_merge.csv', index_col=0,)\n",
    "df1 = pd.read_csv('perfumes_temp13.csv', index_col=0, header=None)\n",
    "df2 = pd.read_csv('perfumes_temp14.csv', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# append dfs to merge\n",
    "df1 = df1.append(df2)\n",
    "\n",
    "\n",
    "df1.columns=['name', 'image', 'designer', 'accords', 'notes', 'description', 'rating', 'rating_count', \n",
    "             'love', 'like', 'dislike', 'winter', 'spring', 'summer', 'fall', 'day', 'night', 'reminds', \n",
    "             'reviews_dict']\n",
    "\n",
    "df = df.append(df1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# save df to csv\n",
    "df.to_csv('perfume_merge.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Drop duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dont_touch = pd.read_csv('perfume_merge.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dont_touch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_dont_touch.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = range(0,df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df.index==range(0,df.shape[0])).count(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and merge duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all rows that have the same name\n",
    "df[df.duplicated('name', keep=False)].groupby('designer')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identify one of the two copies to delete\n",
    "to_delete_1 = [2094, 2638, 2738, 2741, 3409, 9852, 37758, 40523, 43831, 1371, \n",
    "               1557, 1637, 1418, 1419, 2659, 32101, 1438, 1412, 1410, 1413, \n",
    "               1414, 1415, 1564, 1461, 1416, 1631, 1666, 1482, 1506, 1417, 5327, \n",
    "               1610, 1373, 1504, 1638, 1421, 29539, 1554, 1639, 1439, 1374, 1375, \n",
    "               1376, 1464, 1465, 1578, 1577, 1405, 1480, 1481, 1406, 1407, 1408, \n",
    "               1625, 1626, 1627, 1628, 1629, 1409, 1411, 1466, 1467, 1468, 32179, \n",
    "               1474, 1475, 1476, 1477, 1478, 1633, 1479, 1463, 1519, 1377, 22278,\n",
    "               1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1636, \n",
    "               1594, 1595, 1576, 1575, 1425, 1522, 3231, 1523, 1551, 1640, 3234, \n",
    "               3238, 20072, 1378, 1667, 1420, 1641, 3244, 11379, 3391, 1665, 1434, \n",
    "               1527, 1404, 1569, 1570, 1571, 1573, 1574, 1579, 1580, 1581, 1582, \n",
    "               1583, 1483, 1484, 1485, 1486, 1487, 1488, 1490, 1491, 1492, 1493, \n",
    "               1494, 1495, 1496, 1497, 1634, 1517, 1661, 1556, 1402, 1518, 1662, \n",
    "               42167, 1432, 1663, 1403, 1547, 3383, 3386, 2098, 1664, 1489, 1498, \n",
    "               1499, 1602, 1441, 3250, 1502, 1503, 3253, 1642, 1643, 3255, 1379, \n",
    "               35948, 1596, 1544, 1635, 1545, 1542, 1548, 1549, 1550, 1457, 1658, \n",
    "               3369, 1526, 1458, 1401, 1669, 1660, 1597, 1598, 1381, 1380, 1520, \n",
    "               1382, 14542, 1443, 1383, 1444, 1668, 3268, 1505, 1612, 1385, 1533, \n",
    "               1454, 1655, 1656, 1430, 1657, 1455, 1632, 1456, 15041, 1400, 1540, \n",
    "               1539, 1541, 1543, 1386, 3272, 1387, 1500, 1501, 1521, 17266, 1389, \n",
    "               1388, 1390, 1536, 1614, 1613, 1426, 22799, 1651, 1652, 1399, 1653, \n",
    "               3352, 1565, 1566, 1567, 4572, 1568, 35628, 3357, 3360, 1525, 1534,\n",
    "               3278, 3286, 3284, 20103, 3288, 1223, 1524, 4626, 1552, 1558, 1507, \n",
    "               1508, 1509, 1510, 1559, 4644, 3338, 3336, 1396, 1649, 1619, 1620, \n",
    "               1621, 1622, 1560, 1623, 1428, 1555, 1650, 1608, 1391, 1645, 1427, \n",
    "               1392, 1515, 1514, 1615, 1395, 1447, 1646, 1394, 1393, 1511, 1512, \n",
    "               1553, 3317, 4649, 1599, 1600, 1601, 14450, 1562, 1537, 1618, 3330, \n",
    "               3332, 1648, 1397, 1563, 1398, 1647, 1449, 1450, 1616, 1451, 3299, \n",
    "               3300, 1452, 1617, 1561, 5749, 3313, 24831, 4628, 6991\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.duplicated('name', keep=False)].sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# actually delete one of the two copies\n",
    "df = df.drop(to_delete_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check what duplicated entries are left\n",
    "df[df.duplicated('name', keep=False)].groupby('designer')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df.name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and drop empty accords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find empty accords\n",
    "df[df.duplicated('accords', keep=False)].sort_values(by='accords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop 'em\n",
    "df = df.drop(df[df.accords == '[]'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and drop empty notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find empty notes\n",
    "df[df.duplicated('notes', keep=False)].sort_values(by='notes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop those\n",
    "df = df.drop(df[df.notes == 'NaN'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset index again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = range(0,df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df.index==range(0,df.shape[0])).count(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix weird perfume names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_names(name):\n",
    "    \"\"\"\n",
    "    input: name from df.name\n",
    "    returns: cleaned df.name\n",
    "    \"\"\"\n",
    "    name = name.replace('`', \"'\")\n",
    "    name = name.replace('’', \"'\")\n",
    "    name = name.replace('&amp;', ' and ')\n",
    "    name = name.replace('…', '...')\n",
    "    name = name.replace('№', 'No.')\n",
    "    name = name.replace('[', \"\")\n",
    "    name = name.replace(']', \"\")   \n",
    "    name = name.replace('®', \"\")\n",
    "    name = name.replace('–', '-')\n",
    "    name = name.replace('±', '')\n",
    "    name = name.replace('´', \"'\")\n",
    "    name = name.replace('♥', '')\n",
    "    name = name.replace('™', '')\n",
    "    name = name.replace('‘', \"'\")\n",
    "    name = name.replace('|', \"\")\n",
    "    name = name.replace('△', \"\")\n",
    "    name = name.replace('▽', \"\")\n",
    "    name = name.replace('○', \"\")\n",
    "    name = name.replace('$', \"\")\n",
    "    name = name.replace('&gt;', \">\")\n",
    "    name = name.replace('&lt;', \"<\")\n",
    "    name = name.replace('@', \"at\")\n",
    "    name = name.replace('D/', \"d'\")\n",
    "    name = name.replace('/L ', \"\")\n",
    "    name = name.replace('mat;', \"Mat\")\n",
    "    name = name.replace('é', \"e\")\n",
    "    name = name.replace('à', \"a\")\n",
    "    name = name.replace('É', \"E\")\n",
    "    name = name.replace('è', \"e\")\n",
    "    name = name.replace('  ', \" \")\n",
    "    name = name.replace('\"', \"\")\n",
    "    name = name.replace('ì', \"i\")    \n",
    "    name = name.replace(' + > ', \" \")    \n",
    "    name = name.replace('<3', \"\")   \n",
    "    name = name.replace('k̠h̠', \"kh\") \n",
    "    name = name.replace('​', ' ')\n",
    "    \n",
    "    return name\n",
    "df['name'] = df.name.apply(fix_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the ones that weren't cleaned by above definition\n",
    "df.loc[20772, 'name'] = 'Base Man Linn Young for men'\n",
    "df.loc[20773, 'name'] = 'Club Man Linn Young for men'\n",
    "df.loc[20774, 'name'] = 'Steel Masculino Linn Young for men'\n",
    "df = df.drop([41538])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check what names are weird ones thta need to be cleaned\n",
    "k=0\n",
    "for j in df.name.tolist():\n",
    "    if not all(i.isalnum() or i.isspace() or i in \"^¢=+;/?*#,%°:'.-()!\" for i in j):\n",
    "        k+=1\n",
    "        print (j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset index again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = range(0,df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df.index==range(0,df.shape[0])).count(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Get document term matrices of notes and accords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts:\n",
    "word2vec_sklearn = feature_extraction.text.CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get sparse matrix of notes\n",
    "notes_df = pd.DataFrame(word2vec_sklearn.fit_transform(df.notes).toarray(), \n",
    "                        columns = word2vec_sklearn.get_feature_names(), \n",
    "                        index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get sparse matrix of accords\n",
    "accords_df = pd.DataFrame(word2vec_sklearn.fit_transform(df.accords).toarray(), \n",
    "                          columns=word2vec_sklearn.get_feature_names(), \n",
    "                          index = df.index).ix[:,120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.reminds != '[]'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4bdb709e2036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'https.*?jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_reminds'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreminds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_reminds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def clean_reminds(remind):\n",
    "    \"\"\"\n",
    "    input: df.remind, string\n",
    "    returns: get the image link from reminds column and put into clean_reminds\n",
    "    \"\"\"\n",
    "    if remind != '[]':\n",
    "        return re.findall(r'https.*?jpg', remind)\n",
    "\n",
    "df['clean_reminds'] = df.reminds.apply(clean_reminds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cosine similarity for notes and accords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_notes = cosine_similarity(notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_accords = cosine_similarity(accords_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cos_accords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_notes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save cosine similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('cos_accords.npy', cos_accords)\n",
    "np.save('cos_notes.npy', cos_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files\n",
    "Save cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('perfume_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('perfume_cleaned.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cos similarity matrix for notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_notes = np.load('cos_notes.npy')\n",
    "# cos_accords = np.load('cos_accords.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "# Validation!\n",
    "## Get similarity score comparisons for test and random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_dict(dataframe):\n",
    "    \"\"\"\n",
    "    input: dataframe, perfumes dataframe\n",
    "    returns: dict, keys are indices of perfumes, values are indices \n",
    "             of \"reminds me of\" perfumes that are contained in a list\n",
    "    \"\"\"\n",
    "    # make new dict\n",
    "    validation_dict = {}\n",
    "\n",
    "    # for each row\n",
    "    for df_ind in df[df.reminds != '[]'].index:\n",
    "        # for each reminds\n",
    "        for small_image in df.ix[df_ind].clean_reminds:\n",
    "            # get index\n",
    "            try:\n",
    "                remind_index = df[df.image==('https://fimgs.net/images/perfume/nd.' + small_image[35:])].index[0]\n",
    "            except IndexError:\n",
    "                continue\n",
    "                \n",
    "            # make dict\n",
    "            try:\n",
    "                validation_dict[df_ind] += [remind_index]\n",
    "            except KeyError:\n",
    "                validation_dict[df_ind] = [remind_index]\n",
    "    return validation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_dict = validation_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similarity_score_comparisons(validation_dict, cos_matrix):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        validation_dict: dict, keys are indices of perfumes, values are indices \n",
    "                         of \"reminds me of\" perfumes that are contained in a list\n",
    "        cos_matrix: cosine similarity matrix, numpy\n",
    "    returns: get similarity scores for test set and random set; two lists\n",
    "    \"\"\"\n",
    "    test_sim_score = []\n",
    "    random_sim_score = []\n",
    "    \n",
    "    for key in validation_dict.keys():\n",
    "        for item in validation_dict[key]:\n",
    "            test_sim_score.append(cos_matrix[key][item])\n",
    "    print ('test mean and std:', np.mean(test_sim_score), np.std(test_sim_score))\n",
    "\n",
    "    for i in range(len(test_sim_score)):\n",
    "        random_sim_score.append(cos_matrix[np.random.randint(len(cos_matrix))][np.random.randint(len(cos_matrix))])\n",
    "    print ('random mean and std:', np.mean(random_sim_score), np.std(random_sim_score))\n",
    "    \n",
    "    return test_sim_score, random_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cosine similarities for test and random \"notes\"\n",
    "test_sim_notes, random_sim_notes = get_similarity_score_comparisons(validation_dict, cos_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cosine similarities for test and random \"accords\"\n",
    "test_sim_accords, random_sim_accords = get_similarity_score_comparisons(validation_dict, cos_accords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_graphs(test_sim, random_sim):\n",
    "    \"\"\"\n",
    "    input: test_sim and random_sim, two lists\n",
    "    returns: None\n",
    "    \"\"\"\n",
    "    # plot scatterplots for test_sim and random_sim\n",
    "    pyplot.figure()\n",
    "    pyplot.plot(test_sim, marker='.', linewidth=0, alpha=0.2, color='salmon')\n",
    "    pyplot.plot(random_sim, marker='.', linewidth=0, alpha=0.2, color='cornflowerblue')\n",
    "    pyplot.ylim([0,1])\n",
    "    pyplot.ylabel('cosine-similarity score')\n",
    "    pyplot.xlim([0,len(test_sim)])\n",
    "    pyplot.xlabel('perfume')\n",
    "    \n",
    "    # plot similarity score curves\n",
    "    pyplot.figure()\n",
    "    pyplot.plot(sorted(test_sim), 'salmon')\n",
    "    pyplot.plot(sorted(random_sim), 'cornflowerblue')\n",
    "    pyplot.ylim([0,1])\n",
    "    pyplot.xlim([0, len(random_sim)])\n",
    "    \n",
    "    # plot similarity score cumsum curves\n",
    "    pyplot.figure()\n",
    "    pyplot.plot(np.cumsum(sorted(test_sim, reverse=True)), 'salmon')\n",
    "    pyplot.plot(np.cumsum(sorted(random_sim, reverse=True)), 'cornflowerblue')\n",
    "    pyplot.xlim([0, len(random_sim)])\n",
    "    \n",
    "    # plot histograms\n",
    "    pyplot.figure()\n",
    "    sns.distplot(test_sim, bins=50, color='salmon', kde=False, hist=True, kde_kws={\"shade\": True})\n",
    "    sns.distplot(random_sim, bins=50, color='cornflowerblue', kde=False, hist=True, kde_kws={\"shade\": True})\n",
    "    sns.set_style('white')\n",
    "    pyplot.xlim([0,1])\n",
    "    pyplot.xlabel('cosine similarity score')\n",
    "    pyplot.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes_plot = plot_graphs(test_sim_notes, random_sim_notes)\n",
    "pyplot.savefig('notes_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_graphs(test_sim_accords, random_sim_accords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_percentile(values_compiled):\n",
    "    \"\"\"\n",
    "    input: values_compiled, where [0] is the p values of the true population and [1:] is the p values of the \"fake\" populations\n",
    "    returns: percentiles of true population values\n",
    "    \"\"\"\n",
    "    from scipy import stats\n",
    "\n",
    "    values = [i[0] for i in values_compiled]\n",
    "\n",
    "    return stats.percentileofscore(values, values[0], kind='rank'), values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permutation_test(test_set, random_set, number_of_loops):\n",
    "    \"\"\"\n",
    "    input: test_set and random_set; two lists\n",
    "           number_of_loops: int, how many iterations should permutation test loop through\n",
    "    returns: permutation test values (percentile ranking and value) using two sample t-test as test statistic\n",
    "    \"\"\"\n",
    "    from scipy.stats import ttest_ind\n",
    "    true_stat = ttest_ind(test_set, random_set, equal_var=False)\n",
    "\n",
    "    # merge test and random sets\n",
    "    mixed = test_set + random_set\n",
    "    \n",
    "    fake_stats = []\n",
    "    for i in range(number_of_loops):\n",
    "        # make indices for the two diferent populations\n",
    "        pop_1 = mixed[:]\n",
    "        pop_1_index = np.random.choice(len(mixed), len(mixed)//2, replace=False)\n",
    "        \n",
    "        # make pop_2\n",
    "        pop_2 = []\n",
    "        for number in pop_1_index:\n",
    "            pop_2.append(pop_1[number])\n",
    "\n",
    "        # make pop_1\n",
    "        for j in sorted(pop_1_index.tolist(), reverse=True):\n",
    "            del (pop_1[j])\n",
    "\n",
    "        fake_stats.append(ttest_ind(pop_1, pop_2, equal_var=False))\n",
    "        \n",
    "    fake_stats.insert(0, true_stat)\n",
    "    \n",
    "    pct, val = get_percentile(fake_stats)\n",
    "    return pct, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentile_acc, values_acc = permutation_test(test_sim_accords, \n",
    "                                      random_sim_accords, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentile_not, values_not = permutation_test(test_sim_notes, \n",
    "                                          random_sim_notes, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (percentile_acc)\n",
    "print(percentile_not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----\n",
    "# Get recommendations and ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Bayesian rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['rating_mean'] = df.rating.mean()\n",
    "df['rating_ct_mean'] = df.rating_count.mean()\n",
    "\n",
    "# get bayesian rating score for each perfume\n",
    "df['bayesian_rating'] = ((df.rating_ct_mean*df.rating_mean) + (df.rating_count * df.rating_count * df.rating)) / (df.rating_ct_mean + df.rating_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ebay_link(perfume_string):\n",
    "    \"\"\"\n",
    "    input: perfume_string, string\n",
    "    returns: link to ebay page, string\n",
    "    \"\"\"\n",
    "    import ebaysdk\n",
    "    from ebaysdk.finding import Connection as finding\n",
    "    \n",
    "    api = finding(siteid='EBAY-US', \n",
    "                  appid='CandiceY-Bettersc-PRD-b8dfd86bc-41f85e11',\n",
    "                  config_file=None)\n",
    "\n",
    "    api.execute('findItemsAdvanced', {\n",
    "        'keywords': perfume_string,\n",
    "        'categoryId' : ['180345'],\n",
    "        'paginationInput': {\n",
    "            'entriesPerPage': '25',\n",
    "            'pageNumber': '1' \n",
    "        },\n",
    "        'sortOrder': 'CurrentPriceHighest'\n",
    "    })\n",
    "\n",
    "    dictstr = api.response.dict()\n",
    "    return dictstr['itemSearchURL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendations_df(perfume_string, df, cos_matrix, evaluator):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        perfume_string: str, input perfume to get recommendation for\n",
    "        df: perfume database\n",
    "        cos_df: dataframe; cosine similarity matrix\n",
    "    returns: dataframe, ranked by highest recommendation\n",
    "    \"\"\"\n",
    "    if perfume_string in list(df.name):\n",
    "        # get index of perfume string\n",
    "        perfume_string_index = df[df.name == perfume_string].index\n",
    "        \n",
    "        # get cos-similarity values for that perfume\n",
    "        similarity_vals = cos_matrix[perfume_string_index]\n",
    "        \n",
    "        # get indices for cos-similarity values\n",
    "        ranked_recs = np.argsort(similarity_vals)[0][:-22:-1]\n",
    "        \n",
    "        # get dataframe of top 20 most similar perfumes\n",
    "        df_to_return = df.iloc[ranked_recs]\n",
    "        df_to_return = df_to_return.drop(perfume_string_index)\n",
    "        \n",
    "        top_hit = df_to_return.sort_values(by='bayesian_rating', ascending=False).head(1)\n",
    "        rec_name = top_hit.name.tolist()[0]\n",
    "        \n",
    "        rec_why = top_hit[evaluator].tolist()[0][2:-2].split(\"), ('\")\n",
    "        rec_why = rec_why[0].split(\"', '\")\n",
    "\n",
    "        \n",
    "        orig_why = df.ix[perfume_string_index][evaluator].tolist()[0][2:-2].split(\"), ('\")\n",
    "        orig_why = orig_why[0].split(\"', '\")\n",
    "\n",
    "        image = top_hit.image\n",
    "                \n",
    "        final_why = []\n",
    "\n",
    "        for i in orig_why:\n",
    "            if i in rec_why:\n",
    "                final_why.append(i)\n",
    "\n",
    "        if len(final_why) == 1:\n",
    "            statement = 'We recommend this fragrance because it shares ' + str(final_why[0]).lower() + ' notes with ' + str(perfume_string) + '.'\n",
    "        else:\n",
    "            new_s = \"\"\n",
    "            for i in final_why[:-1]:\n",
    "                new_s += (i + ', ')\n",
    "            statement = 'We recommend this fragrance because it shares ' + new_s.lower() + ' and ' + str(final_why[-1]).lower() + ' notes with ' + str(perfume_string) + '.'\n",
    "\n",
    "        ebay = get_ebay_link(rec_name)\n",
    "        \n",
    "        rating = round(top_hit.rating.tolist()[0], 2)\n",
    "        \n",
    "        rating_count = int(top_hit.rating_count.tolist()[0])\n",
    "        \n",
    "        return rec_name, statement, ebay, image.iloc[0], rating, rating_count\n",
    "    \n",
    "    else:\n",
    "        rec_name = \"Sorry, we don't have enough data about this fragrance to construct a recommendation.\"\n",
    "        statement = None\n",
    "        ebay = None\n",
    "        image = None\n",
    "        rating = None\n",
    "        rating_count = None\n",
    "        return rec_name, statement, ebay, image, rating, rating_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get recommendation - notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Burberry Men Burberry for men',\n",
       " 'We recommend this fragrance because it shares mint, lavender, sandalwood, jasmine, geranium, musk, oakmoss, cedar,  and amber notes with Cool Water Davidoff for men.',\n",
       " 'http://www.ebay.com/sch/180345/i.html?_nkw=Burberry+Men+Burberry+for+men&_ddo=1&_ipg=25&_pgn=1&_sop=3',\n",
       " 'https://fimgs.net/images/perfume/nd.817.jpg',\n",
       " 0.79,\n",
       " 920)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_df('Cool Water Davidoff for men', df, cos_notes, 'notes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "STOPWORDS.update(['perfume', 'perfumes', 'note', 'notes', 'smell', 'scent', 'fragrance', 'one', 'bottle'])\n",
    "word_string = df.reviews_dict[19838]\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "                          background_color='white',\n",
    "                          width=4800,\n",
    "                          height=2000\n",
    "                         ).generate(word_string)\n",
    "\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get names to put into website for dropdown menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_names = df.name.tolist()\n",
    "a = []\n",
    "for all_name in all_names:\n",
    "    all_name = all_name.replace('\"', \"'\")\n",
    "    a.append(all_name)\n",
    "\n",
    "\n",
    "all_names.replace"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
