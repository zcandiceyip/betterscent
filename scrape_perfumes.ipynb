{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open perfume urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"perfume_links_all.txt\", \"rb\") as fp:\n",
    "    perfume_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort perfume list to figure out which perfumes to scrape first\n",
    "How to rank: I hypothesize that the more number of perfumes, the more popular the brand overall, which means the more reviews and user data each perfume of that brand would have. So, I counted the number of perfumes each brand had, ranked the perfumes based on number per brand in descending order, and started scraping the most productive brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perfume_dict(perfume_list):\n",
    "    \"\"\"\n",
    "    input: perfume_list, list of perfume urls\n",
    "    returns: dictionary where the keys are designers and the values are number of perfumes per designer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create perfume dictionary\n",
    "    perfumes_dict = {}\n",
    "    for i in perfume_list:\n",
    "        try:\n",
    "            perfumes_dict[i.split('/')[4]] += 1\n",
    "        except KeyError:\n",
    "            perfumes_dict[i.split('/')[4]] = 1\n",
    "            \n",
    "    return perfumes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get perfumes dict\n",
    "perfumes_dict = perfume_dict(perfume_list)\n",
    "\n",
    "# Sort perfume list by perfume count\n",
    "sorted_perfumes = sorted(perfumes_dict.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_perfume_urls(sorted_perfumes_tuples, perfume_list):\n",
    "    \"\"\"\n",
    "    input: \n",
    "    sorted_perfumes_tuples: nested list of tuples where [0] is designer and [1] is designer count\n",
    "    perfume_list: list of perfume urls\n",
    "    returns: list of strings of perfume urls, sorted by most popular designer\n",
    "    \"\"\"\n",
    "    sorted_perfume_urls = []\n",
    "    \n",
    "    for sorted_perfume in sorted_perfumes_tuples:\n",
    "        for perfume_url in perfume_list:\n",
    "            if perfume_url.startswith('https://www.fragrantica.com/perfume/' + sorted_perfume[0]):\n",
    "                sorted_perfume_urls.append(perfume_url)\n",
    "                \n",
    "    return sorted_perfume_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get sorted perfume urls\n",
    "sorted_perfume_urls = sort_perfume_urls(sorted_perfumes, perfume_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(sorted_perfume_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save sorted perfume urls\n",
    "with open(\"sorted_perfumes.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(sorted_perfume_urls, fp)\n",
    "\n",
    "# open sorted perfume urls\n",
    "with open(\"sorted_perfumes.txt\", \"rb\") as fp:   # Unpickling\n",
    "    sorted_perfume_urls = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_perfume_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape perfume data: \n",
    "- 1300 pages/hour if average of 1 second wait\n",
    "- 2142 pages/hour if average of 0.5 second wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(soup):\n",
    "    \"\"\"\n",
    "    input: soup parsed by BeautifulSoup\n",
    "    returns: a list of features\n",
    "    \"\"\"\n",
    "    \n",
    "    # designer\n",
    "    try:\n",
    "        designer = str(soup.find_all(itemprop='name')[0])[22:-7]\n",
    "    except:\n",
    "        designer = np.nan\n",
    "    \n",
    "    # name\n",
    "    try:\n",
    "        name = str(soup.find_all(itemprop='name')[1])[22:-7]\n",
    "    except:\n",
    "        name = np.nan\n",
    "    \n",
    "    # image url\n",
    "    try:\n",
    "        image = str(soup.find_all(itemprop='image')).split('src=\"')[1].split('\" style')[0]\n",
    "    except:\n",
    "        image = np.nan\n",
    "\n",
    "    # love/like/dislike/winter/spring/summer/fall/day/night\n",
    "    try:\n",
    "        diagramresult = soup.find('div', attrs={'id':'diagramresult'})\n",
    "        diagram_result_divs = diagramresult.find_all('div')\n",
    "        love = int(str(diagram_result_divs[0]).split(\"height: \")[1].split('px')[0])/100\n",
    "        like = int(str(diagram_result_divs[1]).split(\"height: \")[1].split('px')[0])/100\n",
    "        dislike = int(str(diagram_result_divs[2]).split(\"height: \")[1].split('px')[0])/100\n",
    "        winter = int(str(diagram_result_divs[3]).split(\"height: \")[1].split('px')[0])/100\n",
    "        spring = int(str(diagram_result_divs[4]).split(\"height: \")[1].split('px')[0])/100\n",
    "        summer = int(str(diagram_result_divs[5]).split(\"height: \")[1].split('px')[0])/100\n",
    "        fall = int(str(diagram_result_divs[6]).split(\"height: \")[1].split('px')[0])/100\n",
    "        day = int(str(diagram_result_divs[7]).split(\"height: \")[1].split('px')[0])/100\n",
    "        night = int(str(diagram_result_divs[8]).split(\"height: \")[1].split('px')[0])/100\n",
    "    except:\n",
    "        diagramresult = np.nan\n",
    "        diagram_result_divs = np.nan\n",
    "        love = np.nan\n",
    "        like = np.nan\n",
    "        dislike = np.nan\n",
    "        winter = np.nan\n",
    "        spring = np.nan\n",
    "        summer = np.nan\n",
    "        fall = np.nan\n",
    "        day = np.nan\n",
    "        night = np.nan\n",
    "    \n",
    "    # accords\n",
    "    try:\n",
    "        accords = soup.find('div', attrs = {'id':'prettyPhotoGallery'}).find_all('div')\n",
    "        def clean_accords(main_accords):\n",
    "            all_accords = []\n",
    "            for i in range(1, len(main_accords[0].find_all('div')), 3):\n",
    "                accord = (str(main_accords[0].find_all('div')[i]).split('z-index: 60;\">')[1].split('<')[0],\n",
    "                          int(str(main_accords[0].find_all('div')[i]).split('width: ')[2].split('px')[0])/130)\n",
    "                all_accords.append(accord)\n",
    "            return all_accords\n",
    "        accords = clean_accords(accords)\n",
    "    except:\n",
    "        accords = np.nan\n",
    "    \n",
    "    # rating\n",
    "    try:\n",
    "        rating = float(str(soup.find_all('span', attrs={'itemprop' : 'ratingValue'})[0]).split('\">')[1].split('<')[0])/5\n",
    "    except:\n",
    "        rating = np.nan\n",
    "    \n",
    "    # rating count\n",
    "    try:\n",
    "        rating_count = int(str(soup.find_all('span', attrs={'itemprop' : 'ratingCount'})[0]).split('\">')[1].split('<')[0])\n",
    "    except:\n",
    "        rating_count = np.nan\n",
    "    \n",
    "    # description\n",
    "    try:\n",
    "        description = soup.find('div', attrs={'itemprop':'description'}).get_text()\n",
    "    except:\n",
    "        description = np.nan\n",
    "    \n",
    "    # reminds me of...\n",
    "    try:\n",
    "        reminds = soup.find_all('div', attrs={'class':'votes'})\n",
    "        remind_list = reminds[0].find_all('img')\n",
    "        def clean_reminds(reminds_list):\n",
    "            all_remind = []\n",
    "            for reminds_of in reminds_list:\n",
    "                remind_dirty = str(reminds_of).split('src=\"')[1].split('\"')\n",
    "                all_remind.append((remind_dirty[2], remind_dirty[0]))\n",
    "            return all_remind\n",
    "        reminds = clean_reminds(remind_list)\n",
    "    except:\n",
    "        reminds = np.nan\n",
    "    \n",
    "    # notes\n",
    "    try:\n",
    "        notes = []\n",
    "        for j in soup.find_all('span', attrs={'class': 'rtgNote'}):\n",
    "            notes.append(str(j.img).split('alt=\"')[1].split('\" class')[0])\n",
    "    except:\n",
    "        notes = np.nan\n",
    "    \n",
    "    # reviews\n",
    "    try:\n",
    "        reviews_dirty = soup.find_all('div', attrs={'class':'pwq'})\n",
    "        reviews_dict = {}\n",
    "        for review_dirty in reviews_dirty:\n",
    "            reviews_dict[review_dirty.find('b').get_text()] = review_dirty.find('p').get_text()\n",
    "        reviews_dict    \n",
    "    except:\n",
    "        reviews_dict = np.nan\n",
    "        \n",
    "    return [name, image, designer, accords, notes, description, rating, \n",
    "            rating_count, love, like, dislike, winter, spring, summer, \n",
    "            fall, day, night, reminds, reviews_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape url!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def scrape_perfume_urls(sorted_perfume_urls):\n",
    "    # set index count\n",
    "    n = 0\n",
    "\n",
    "    # get webpage and scrape features\n",
    "    for perf_url in sorted_perfume_urls:\n",
    "        # set headers\n",
    "        user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "        headers={'User-Agent':user_agent,} \n",
    "\n",
    "        # request\n",
    "        request=urllib.request.Request(perf_url,None,headers) #The assembled request\n",
    "        try:\n",
    "            response = urllib.request.urlopen(request, timeout=10)\n",
    "            data = response.read() # The data u need\n",
    "        except:\n",
    "            print (n, 'iswrong')\n",
    "            continue\n",
    "\n",
    "        time.sleep(random.random())\n",
    "\n",
    "        # parse and get features\n",
    "        designer_soup = BeautifulSoup(data, 'html.parser')\n",
    "        single_url = get_features(designer_soup)\n",
    "\n",
    "        # append to dataframe\n",
    "        df.loc[n] = single_url\n",
    "\n",
    "        # increase index count\n",
    "        n += 1\n",
    "        print (n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_a = time.time()\n",
    "\n",
    "# set up dataframe\n",
    "df = pd.DataFrame(columns=['name', 'image', 'designer', 'accords', 'notes', 'description', 'rating', \n",
    "                           'rating_count', 'love', 'like', 'dislike', 'winter', 'spring', 'summer', \n",
    "                           'fall', 'day', 'night', 'reminds', 'reviews_dict'])\n",
    "\n",
    "# scrape perfume urls\n",
    "scrape_perfume_urls(sorted_perfume_urls)\n",
    "\n",
    "# save df to csv\n",
    "df.to_csv('perfumes_temp.csv', mode='a', header=False)\n",
    "\n",
    "time_b = time.time()\n",
    "print(time_b - time_a)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
